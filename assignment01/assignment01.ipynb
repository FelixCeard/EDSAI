{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5beddcfb",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "Elements of Data Science and Artificial Intelligence\n",
    "<br>\n",
    "Winter Semester 2022/2023\n",
    "<br>\n",
    "Saarland University\n",
    "\n",
    "Prof. Dr. Dittrich\n",
    "<br>\n",
    "Prof. Dr. Hoffmann\n",
    "<br>\n",
    "Prof. Dr. Schiele\n",
    "<br>\n",
    "Dr. Schuster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30e2a88",
   "metadata": {},
   "source": [
    "The first assignment is exclusively about Python and asks you to solve small tasks. Insert your solution in the cells marked with `TODO: implement`. For each exercise, we have written a few unit tests so you are able to check your implementation right away (keep in mind that passing the unit tests does not necessarily mean your implementation computes the desired output for all possible inputs of your function!). In case you have questions, feel free to use our [forum](https://edsai.cs.uni-saarland.de/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d342da",
   "metadata": {},
   "source": [
    "**You are not allowed to use third-party libraries or additional Python modules unless otherwise specified.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6f6d2f",
   "metadata": {},
   "source": [
    "#### Submission Details\n",
    "Upload your submission to our [CMS](https://cms.sic.saarland/edsai2223/) in groups of two to three students until **November 23, 2022 23:59**. Late submissions will not be graded! Your submission should only contain this **.ipynb** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb064757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the unittests\n",
    "%run -i assignment01_unittests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f2ea3",
   "metadata": {},
   "source": [
    "## Exercise 1: Statistical computations (4 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cd9537",
   "metadata": {},
   "source": [
    "### a) Arithmetic mean (1 Points)\n",
    "Implement a function `mean(input_list)` that returns the arithmetic mean of the elements contained in `input_list`. The arithmetic mean is defined as follows:\n",
    "$$\n",
    "\\text{mean}([a_{0}, \\cdots, a_{n-1}]) = \\frac{1}{n}\\sum_{i=0}^{n-1} a_{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9a98d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = lambda x: (1/len(x))*sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfc77295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_large (__main__.MeanTest) ... ok\n",
      "test_negative (__main__.MeanTest) ... ok\n",
      "test_same (__main__.MeanTest) ... ok\n",
      "test_small (__main__.MeanTest) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.009s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": "<unittest.main.TestProgram at 0x15932df5f70>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run tests\n",
    "# Note: due to floating point precision, we test for almost equality\n",
    "# see: https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertAlmostEqual\n",
    "unittest.main(argv=['ignored', '-v', 'MeanTest'], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2000dcee",
   "metadata": {},
   "source": [
    "### b) Variance (1.5 Points)\n",
    "Implement a function `variance(input_list)` that returns the variance of the elements contained in *input_list*. The variance is defined as follows:\n",
    "\n",
    "$$\n",
    "\\text{variance}([a_{0}, \\cdots, a_{n-1}]) = \\frac{\\sum_{i=0}^{n-1} (a_{i}-\\mu)^2}{n - 1}\n",
    "$$\n",
    "where:\n",
    "* $[a_{0}, \\cdots, a_{n-1}]$ is a list of integers\n",
    "* $\\mu$ is the mean value of the elements in the list\n",
    "* $n$ is the number of elements in the list\n",
    "\n",
    "You may assume that *input_list* contains at least two elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da9cd192",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = lambda x: (1/(len(x)-1)) * sum([(a-mean(x))**2 for a in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5c86530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_large (__main__.VarTest) ... ok\n",
      "test_negative (__main__.VarTest) ... ok\n",
      "test_same (__main__.VarTest) ... ok\n",
      "test_small (__main__.VarTest) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.013s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": "<unittest.main.TestProgram at 0x15929a82790>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run tests\n",
    "# Note: due to floating point precision, we test for almost equality\n",
    "# see: https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertAlmostEqual\n",
    "unittest.main(argv=['ignored', '-v', 'VarTest'], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e0f10a",
   "metadata": {},
   "source": [
    "### c) Median (1.5 Points)\n",
    "Implement a function `median(input_list)` that returns the median of a given *input_list*. The median is the value separating the lower half from the upper half of a dataset and is defined as follows:\n",
    "\n",
    "$$\n",
    "\\text{median}([a_{0}, \\cdots, a_{n-1}]) =\n",
    "\\begin{cases}\n",
    "a_{\\frac{n-1}{2}}, & n \\text{ is odd}\\\\\n",
    "\\frac{1}{2} (a_{\\frac{n}{2}-1} + a_{\\frac{n}{2}})  & n \\text{ is even}\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $[a_{0}, \\cdots, a_{n-1}]$ is a sorted list of integers and $n$ is the number of elements in the list.\n",
    "\n",
    "You may assume that *input_list* is not empty but not necessarily sorted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebcfdf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement\n",
    "def median(x):\n",
    "    x = sorted(x)\n",
    "    n = len(x)\n",
    "    if len(x) % 2 == 1:\n",
    "        return x[int((n-1)/2)]\n",
    "    return 0.5 * (x[int((n/2) - 1)] + x[int(n/2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95993fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_even (__main__.MedianTest) ... ok\n",
      "test_odd (__main__.MedianTest) ... ok\n",
      "test_single (__main__.MedianTest) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.006s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": "<unittest.main.TestProgram at 0x15933128d30>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run tests\n",
    "unittest.main(argv=['ignored', '-v', 'MedianTest'], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6f33a7",
   "metadata": {},
   "source": [
    "## Exercise 2: Complex Functions (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e846eca",
   "metadata": {},
   "source": [
    "### a) Sum of the digits (2 Points)\n",
    "Implement a function `sum_digits(x)` that returns the sum of the digits of a non-negative integer $x$. For example:\n",
    "\n",
    "$$ \\text{sum_digits(1374)} = 1 + 3 + 7 + 4 = 15 $$\n",
    "\n",
    "**Hint:** Make clever use of `div` (Python operator `//`) and `modulo` (Python operator `%`) to extract the individual digits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13714c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_digits(x):\n",
    "    s = 0\n",
    "    while x > 0:\n",
    "        s += x % 10\n",
    "        x = x // 10\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4ce6232",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_long (__main__.SumDigitsTest) ... ok\n",
      "test_one (__main__.SumDigitsTest) ... ok\n",
      "test_small (__main__.SumDigitsTest) ... ok\n",
      "test_zero (__main__.SumDigitsTest) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.007s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": "<unittest.main.TestProgram at 0x1593390d9d0>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run tests\n",
    "unittest.main(argv=['ignored', '-v', 'SumDigitsTest'], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5adcf2a",
   "metadata": {},
   "source": [
    "### b) Levenshtein Distance (3 Points)\n",
    "Implement a function `lev(a,b)` that returns the [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance) between the two strings `a` and `b`. The Levenshtein distance is defined as follows:\n",
    "\n",
    "$$\n",
    "\\text{lev}(a,b) =\n",
    "\\begin{cases}\n",
    "|a| & \\text{if}\\ |b| = 0\\\\\n",
    "|b| & \\text{if}\\ |a| = 0\\\\\n",
    "\\text{lev}(\\text{tail}(a), \\text{tail}(b)) & \\text{if}\\ a[0] = b[0]\\\\\n",
    "1 + \\text{min}(\\text{lev}(\\text{tail}(a), b), \\text{lev}(a, \\text{tail}(b)), \\text{lev}(\\text{tail}(a), \\text{tail}(b))) & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "where:\n",
    "* |a| represents the length of the string _a_\n",
    "* a[0] is the first character of the string _a_\n",
    "* tail(a) is a string of all but the first character of _a_\n",
    "\n",
    "Note: The straightforward recursive implementation is highly inefficient. Therefore, only small strings (up to ~10 characters) should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b38fe24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tail(x):\n",
    "    return x[1:]\n",
    "\n",
    "\n",
    "def lev(a, b):\n",
    "    if len(b) == 0:\n",
    "        return len(a)\n",
    "    if len(a) == 0:\n",
    "        return len(b)\n",
    "    if a[0] == b[0]:\n",
    "        return lev(tail(a), tail(b))\n",
    "    return 1 + min(lev(tail(a), b), lev(a, tail(b)), lev(tail(a), tail(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e0ace3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_equal (__main__.LevenshteinDistanceTest) ... ok\n",
      "test_long (__main__.LevenshteinDistanceTest) ... ok\n",
      "test_normal (__main__.LevenshteinDistanceTest) ... ok\n",
      "test_small (__main__.LevenshteinDistanceTest) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 2.522s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": "<unittest.main.TestProgram at 0x15933645c10>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run tests\n",
    "unittest.main(argv=['ignored', '-v', 'LevenshteinDistanceTest'], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2794002e",
   "metadata": {},
   "source": [
    "## Exercise 3: Classes (5 Points)\n",
    "\n",
    "In this exercise, we will implement a small movie company structure consisting of `Movie`s and `Person`s.\n",
    "\n",
    "The `Movie` class should contain the following data attributes.\n",
    "* `title` - the movie title\n",
    "* `year` - the year in which the movie was released\n",
    "* `genre` - the main genre of the movie, one of [ACTION, DRAMA, THRILLER, COMEDY, HORROR]\n",
    "\n",
    "*Note: We expect the genre to be all in upper case, therefore, e.g. \"Action\" or \"action\" are invalid genres.*\n",
    "\n",
    "The `Movie` class should contain the following methods.\n",
    "* `__init__(self, title, year, genre)`: the constructor taking three arguments $title$, $year$, and $genre$ representing the title, year, and genre; the constructor should check the correctness of the `genre` parameter and print a warning in case a incorrect value was provided (Note: the class will still be created)\n",
    "* `get_title(self)` - returns the `title` of the movie\n",
    "* `get_year(self)` - returns the `year` of the movie\n",
    "* `get_genre(self)` - returns the `genre` of the movie\n",
    "* `__eq__(self, other)` - returns `True` iff the `title`, `year`, and `genre` are equal, `False` otherwise.\n",
    "\n",
    "*Hint: The function `__eq__` overloads the equality operator `==`. If `__eq__` is defined on `x` the expression `x == y` is the same as `x.__eq__(y)`. This allows you to check if two movies `x` and `y` are equal by `x == y`. For more information see [here](https://docs.python.org/3/reference/datamodel.html#object.__eq__).*\n",
    "\n",
    "A `Person` has a `name` and a `surname`. Furthermore, a `Person` can either be an `Actor` or a `Director`, which should be represented using inheritance. A `Director` has exactly one `Movie` that she or he directed. An `Actor` contains a list of `Movie`s she or he participated in.\n",
    "\n",
    "The `Person` class should contain the following methods.\n",
    "* `get_name(self)` - returns the name of the person\n",
    "* `get_surname(self)` - returns the surname of the person\n",
    "\n",
    "The `Director` class should contain the following methods.\n",
    "* `get_movie(self)` - returns the `Movie` directed by the `Director`\n",
    "* `actor_in_movie(self, actor)` - takes an `Actor` and returns `True` iff the `Actor` participated in the `Director`'s `Movie`, `False` otherwise\n",
    "\n",
    "The `Actor` class should contain the following methods.\n",
    "* `get_all_movies(self)` - returns the list of **all** `Movie`s the `Actor` participated in\n",
    "* `get_movies(self, year, genre)` - returns a list containing the `Movies` with the genre `genre` and were released **after** `year`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "789e60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Movie:\n",
    "    def __init__(self, title, year, genre):\n",
    "        if genre.upper() != genre:\n",
    "            print(\"WARNING! genre is not uppercased\")\n",
    "            genre = genre.upper()\n",
    "\n",
    "        self.title = title\n",
    "        self.year = year\n",
    "        self.genre = genre\n",
    "\n",
    "    def get_title(self):\n",
    "        return self.title\n",
    "\n",
    "    def get_year(self):\n",
    "        return self.year\n",
    "\n",
    "    def get_genre(self):\n",
    "        return self.genre\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if type(other) != type(self):\n",
    "            return False\n",
    "\n",
    "        return self.title == other.title and self.year == other.year and self.genre == other.genre\n",
    "\n",
    "class Person:\n",
    "    def __init__(self, name, surname):\n",
    "        self.name = name\n",
    "        self.surname = surname\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "\n",
    "    def get_surname(self):\n",
    "        return self.surname\n",
    "\n",
    "class Director(Person):\n",
    "    def __init__(self, name:str, surname:str, movie:Movie):\n",
    "        super().__init__(name, surname)\n",
    "        self.movie = movie\n",
    "\n",
    "    def get_movie(self):\n",
    "        return self.movie\n",
    "\n",
    "    def actor_in_movie(self, actor):\n",
    "        return self.movie in actor.get_all_movies()\n",
    "\n",
    "class Actor(Person):\n",
    "    def __init__(self, name, surname, movies:[Movie]):\n",
    "        super().__init__(name, surname)\n",
    "\n",
    "        self.movies = movies\n",
    "\n",
    "    def get_all_movies(self):\n",
    "        return self.movies\n",
    "\n",
    "    def get_movies(self, genre, year):\n",
    "        print(self.movies)\n",
    "        return [m for m in self.movies if m.get_year() > year and m.get_genre() == genre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c57b434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_movie_ctor (__main__.MovieTest) ... ok\n",
      "test_movie_eq (__main__.MovieTest) ... ok\n",
      "test_movie_get_genre (__main__.MovieTest) ... ok\n",
      "test_movie_get_title (__main__.MovieTest) ... ok\n",
      "test_movie_get_year (__main__.MovieTest) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.007s\n",
      "\n",
      "OK\n",
      "test_actor_ctor (__main__.PersonTest) ... ok\n",
      "test_actor_get_all_movies (__main__.PersonTest) ... ok\n",
      "test_actor_get_movies_contrained (__main__.PersonTest) ... ok\n",
      "test_actor_inheritance (__main__.PersonTest) ... ok\n",
      "test_director_actor_in_movie (__main__.PersonTest) ... ok\n",
      "test_director_actor_not_in_movie (__main__.PersonTest) ... ok\n",
      "test_director_ctor (__main__.PersonTest) ... ok\n",
      "test_director_get_movie (__main__.PersonTest) ... ok\n",
      "test_director_inheritance (__main__.PersonTest) ... ok\n",
      "test_person_ctor (__main__.PersonTest) ... ok\n",
      "test_person_get_name (__main__.PersonTest) ... ok\n",
      "test_person_get_surname (__main__.PersonTest) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Movie object at 0x00000159334BF070>, <__main__.Movie object at 0x00000159334BFEE0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 12 tests in 0.018s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": "<unittest.main.TestProgram at 0x15929aabdc0>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run tests\n",
    "unittest.main(argv=['ignored', '-v', 'MovieTest'], verbosity=2, exit=False)\n",
    "unittest.main(argv=['ignored', '-v', 'PersonTest'], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7631765",
   "metadata": {},
   "source": [
    "## Exercise 4: Data Cleaning (6 Points)\n",
    "\n",
    "In this exercise, we will again deal with the [IMDb](https://www.imdb.com/interfaces/) dataset from the lecture. However, this time it has been slightly changed, so some data needs to be corrected. First we have to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "011f9696",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                     Title                     Genre              Director  \\\n0  Guardians of the Galaxy   Action,Adventure,Sci-Fi            James Gunn   \n1               Prometheus  Adventure,Mystery,Sci-Fi          Ridley Scott   \n2                    Split           Horror,Thriller    M. Night Shyamalan   \n3                     Sing   Animation,Comedy,Family  Christophe Lourdelet   \n4            Suicide Squad  Action,Adventure,Fantasy            David Ayer   \n\n                                              Actors    Year  Rating  \n0  Chris Pratt, Vin Diesel, Bradley Cooper, Zoe S...  2014.0     8.1  \n1  Noomi Rapace, Logan Marshall-Green, Michael Fa...  2012.0     7.0  \n2  James McAvoy, Anya Taylor-Joy, Haley Lu Richar...  2016.0     7.3  \n3  Matthew McConaughey,Reese Witherspoon, Seth Ma...  2016.0     7.2  \n4  Will Smith, Jared Leto, Margot Robbie, Viola D...  2016.0     6.2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Genre</th>\n      <th>Director</th>\n      <th>Actors</th>\n      <th>Year</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Guardians of the Galaxy</td>\n      <td>Action,Adventure,Sci-Fi</td>\n      <td>James Gunn</td>\n      <td>Chris Pratt, Vin Diesel, Bradley Cooper, Zoe S...</td>\n      <td>2014.0</td>\n      <td>8.1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Prometheus</td>\n      <td>Adventure,Mystery,Sci-Fi</td>\n      <td>Ridley Scott</td>\n      <td>Noomi Rapace, Logan Marshall-Green, Michael Fa...</td>\n      <td>2012.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Split</td>\n      <td>Horror,Thriller</td>\n      <td>M. Night Shyamalan</td>\n      <td>James McAvoy, Anya Taylor-Joy, Haley Lu Richar...</td>\n      <td>2016.0</td>\n      <td>7.3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sing</td>\n      <td>Animation,Comedy,Family</td>\n      <td>Christophe Lourdelet</td>\n      <td>Matthew McConaughey,Reese Witherspoon, Seth Ma...</td>\n      <td>2016.0</td>\n      <td>7.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Suicide Squad</td>\n      <td>Action,Adventure,Fantasy</td>\n      <td>David Ayer</td>\n      <td>Will Smith, Jared Leto, Margot Robbie, Viola D...</td>\n      <td>2016.0</td>\n      <td>6.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(1003, 6)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('imdb_corrupt.csv', delimiter=';')\n",
    "\n",
    "# Print infos\n",
    "display(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b525b78a",
   "metadata": {},
   "source": [
    "### a) Eliminate duplicates (3 Points)\n",
    "\n",
    "One reason for duplicates can be spelling errors or inconsistent usage of (superfluous) special characters or whitespaces. In this exercise, we will make use of the well know edit distance [Hammming distance](https://en.wikipedia.org/wiki/Hamming_distance) to identify duplicate entries due to spelling errors in the movie titles.\n",
    "\n",
    "*Note: This only removes one potential source of error.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b8285",
   "metadata": {},
   "source": [
    "1. Implement a function `hamming_distance_custom(a, b)`, that takes two strings `a` and `b` and returns the hamming distance of both strings. Our custom Hamming distance is defined as follows:\n",
    "\n",
    "$$\n",
    "\\text{hamming_distance_custom}(a,b) =\n",
    "\\begin{cases}\n",
    "\\infty & \\text{if}\\ |a| \\neq |b|\\\\\n",
    "0 & \\text{if}\\ |a| =  0\\\\\n",
    "0 + \\text{hamming_distance_custom}(\\text{tail}(a), \\text{tail}(b)) & \\text{if}\\ a[0] = b[0]\\\\\n",
    "1 + \\text{hamming_distance_custom}(\\text{tail}(a), \\text{tail}(b)) & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where:\n",
    "* |a| represents the length of the string _a_\n",
    "* a[0] is the first character of the string _a_\n",
    "* tail(a) is a string of all but the first character of _a_\n",
    "\n",
    "Note: You can use `math.inf` as $\\infty$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d21aee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def hamming_distance_custom(a, b):\n",
    "    if len(a) != len(b):\n",
    "        return math.inf\n",
    "    if len(a) == 0:\n",
    "        return 0\n",
    "    if a[0] == b[0]:\n",
    "        return 0 + hamming_distance_custom(tail(a), tail(b))\n",
    "    return 1 + hamming_distance_custom(tail(a), tail(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70578c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_different_length (__main__.HammingDistanceTest) ... ok\n",
      "test_empty (__main__.HammingDistanceTest) ... ok\n",
      "test_equal (__main__.HammingDistanceTest) ... ok\n",
      "test_long (__main__.HammingDistanceTest) ... ok\n",
      "test_normal (__main__.HammingDistanceTest) ... ok\n",
      "test_small (__main__.HammingDistanceTest) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.019s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": "<unittest.main.TestProgram at 0x159349fce50>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run tests\n",
    "unittest.main(argv=['ignored', '-v', 'HammingDistanceTest'], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab1d97",
   "metadata": {},
   "source": [
    "2. Check if the movies given in `movies_to_check` contain any spelling mistakes. To do so, iterate over the dataframe `df` and compute the pairwise hamming distance between each title and the movie titles given in `movies_to_check`. If the hamming distance is between 0 and 3 (exclusive, i.e. we have up to two typos), add the potentially misspelled movie title to the `duplicate_movies` list.\n",
    "\n",
    "*Note: This method only identifies potential spelling mistakes. There might be errors that are not detected (e.g. if a character is missing) or very similar movie titles that are detected but in reality, do not contain any spelling mistakes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "825d523a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['Harry Potter and the Deathly Hallows: Part 2',\n 'The Graet Wall',\n 'Frozem',\n 'The Lego Movoe']"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movies_to_check = ['Harry Potter and the Deathly Hallows: Part 1',\n",
    "                   'Star Wars: Episode VII',\n",
    "                   'The Great Wall',\n",
    "                   'Nine Lives',\n",
    "                   'The Lone Ranger',\n",
    "                   'The Lego Movie',\n",
    "                   'Frozen',\n",
    "                   'Lucky Number Slevin'\n",
    "                  ]\n",
    "\n",
    "duplicate_movies = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    for title in movies_to_check:\n",
    "        if 0 < hamming_distance_custom(df.iloc[i][\"Title\"], title) < 3:\n",
    "            duplicate_movies.append(df.iloc[i][\"Title\"])\n",
    "\n",
    "\n",
    "display(duplicate_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f2463f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_duplicates (__main__.DuplicatesTest) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": "<unittest.main.TestProgram at 0x15938090dc0>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run tests\n",
    "unittest.main(argv=['ignored', '-v', 'DuplicatesTest'], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdde50b",
   "metadata": {},
   "source": [
    "3. Afterwards, manually inspect the list of potentially duplicated movies and remove those movies, that actually do not contain any spelling mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "833a5c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_movies = [\n",
    " 'The Graet Wall',\n",
    " 'Frozem',\n",
    " 'The Lego Movoe']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ecbe0",
   "metadata": {},
   "source": [
    "4. Finally, we remove all duplicates from the DataFrame `df` and store the result in the `df` variable again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59f2dbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "              Title                       Genre     Director  \\\n131  The Graet Wall    Action,Adventure,Fantasy  Yimou Zhang   \n341          Frozem  Animation,Adventure,Comedy   Chris Buck   \n798  The Lego Movoe  Animation,Action,Adventure    Phil Lord   \n\n                                                Actors    Year  Rating  \n131      Matt Damon, Tian Jing, Willem Dafoe, Andy Lau  2016.0     6.1  \n341  Kristen Bell, Idina Menzel, Jonathan Groff, Jo...  2013.0     7.5  \n798  Chris Pratt, Will Ferrell, Elizabeth Banks, Wi...  2014.0     7.8  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Genre</th>\n      <th>Director</th>\n      <th>Actors</th>\n      <th>Year</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>131</th>\n      <td>The Graet Wall</td>\n      <td>Action,Adventure,Fantasy</td>\n      <td>Yimou Zhang</td>\n      <td>Matt Damon, Tian Jing, Willem Dafoe, Andy Lau</td>\n      <td>2016.0</td>\n      <td>6.1</td>\n    </tr>\n    <tr>\n      <th>341</th>\n      <td>Frozem</td>\n      <td>Animation,Adventure,Comedy</td>\n      <td>Chris Buck</td>\n      <td>Kristen Bell, Idina Menzel, Jonathan Groff, Jo...</td>\n      <td>2013.0</td>\n      <td>7.5</td>\n    </tr>\n    <tr>\n      <th>798</th>\n      <td>The Lego Movoe</td>\n      <td>Animation,Action,Adventure</td>\n      <td>Phil Lord</td>\n      <td>Chris Pratt, Will Ferrell, Elizabeth Banks, Wi...</td>\n      <td>2014.0</td>\n      <td>7.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(1000, 6)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_duplicates = df[(df['Title'].isin(duplicate_movies))]\n",
    "display(df_duplicates)\n",
    "df.drop(df_duplicates.index, inplace=True, axis='index')\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c91e7d3",
   "metadata": {},
   "source": [
    "### b) Replace missing and erroneous values (3 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f7d45c",
   "metadata": {},
   "source": [
    "1. Missing values are denoted as `NaN` in `Pandas`. List all rows that contain missing values and store them in a new DataFrame `df_missing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "47dc0cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix\\AppData\\Local\\Temp\\ipykernel_13092\\3941044155.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n",
      "  df_missing = df[df.isnull().any(1)]\n"
     ]
    }
   ],
   "source": [
    "# TODO: implement\n",
    "df_missing = df[df.isnull().any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dcc5b25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [Title, Genre, Director, Actors, Year, Rating]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Genre</th>\n      <th>Director</th>\n      <th>Actors</th>\n      <th>Year</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_missing_values (__main__.MissingTest) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_missing_values (__main__.MissingTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\felix\\PycharmProjects\\EDSAI\\assignment01\\assignment01_unittests.py\", line 303, in test_missing_values\n",
      "    self.assertTrue(df_missing.equals(expected_df))\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.004s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<unittest.main.TestProgram at 0x15938103ee0>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df_missing)\n",
    "# Run tests\n",
    "unittest.main(argv=['ignored', '-v', 'MissingTest'], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed97feea",
   "metadata": {},
   "source": [
    "Afterwards, check [IMDB.com](https://www.imdb.com/) for the entries with missing values and manually add them to the DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "28f8c7c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [80], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m df[df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTitle\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m df_missing\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m1\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTitle\u001B[39m\u001B[38;5;124m\"\u001B[39m]] \u001B[38;5;241m=\u001B[39m df[df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTitle\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m df_missing\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m1\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTitle\u001B[39m\u001B[38;5;124m\"\u001B[39m]]\u001B[38;5;241m.\u001B[39mreplace(np\u001B[38;5;241m.\u001B[39mnan, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mQuentin Tarantino\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m df[df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTitle\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m df_missing\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m2\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTitle\u001B[39m\u001B[38;5;124m\"\u001B[39m]] \u001B[38;5;241m=\u001B[39m df[df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTitle\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m df_missing\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m2\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTitle\u001B[39m\u001B[38;5;124m\"\u001B[39m]]\u001B[38;5;241m.\u001B[39mreplace(np\u001B[38;5;241m.\u001B[39mnan, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m7.5\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 6\u001B[0m df[df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTitle\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m df_missing\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m3\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTitle\u001B[39m\u001B[38;5;124m\"\u001B[39m]] \u001B[38;5;241m=\u001B[39m df[df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTitle\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[43mdf_missing\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTitle\u001B[39m\u001B[38;5;124m\"\u001B[39m]]\u001B[38;5;241m.\u001B[39mreplace(np\u001B[38;5;241m.\u001B[39mnan, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2013\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\EDSAI\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1073\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1070\u001B[0m axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m   1072\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[1;32m-> 1073\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaybe_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\EDSAI\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1625\u001B[0m, in \u001B[0;36m_iLocIndexer._getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1622\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot index by location index with a non-integer key\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1624\u001B[0m \u001B[38;5;66;03m# validate the location\u001B[39;00m\n\u001B[1;32m-> 1625\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_integer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1627\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_ixs(key, axis\u001B[38;5;241m=\u001B[39maxis)\n",
      "File \u001B[1;32m~\\PycharmProjects\\EDSAI\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1557\u001B[0m, in \u001B[0;36m_iLocIndexer._validate_integer\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1555\u001B[0m len_axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis(axis))\n\u001B[0;32m   1556\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m len_axis \u001B[38;5;129;01mor\u001B[39;00m key \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m-\u001B[39mlen_axis:\n\u001B[1;32m-> 1557\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msingle positional indexer is out-of-bounds\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mIndexError\u001B[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df[df[\"Title\"] == df_missing.iloc[0][\"Title\"]] = df[df[\"Title\"] == df_missing.iloc[0][\"Title\"]].replace(np.nan, \"Action, Drama, Liebesfilm, Thriller, Kriegsfilm\")\n",
    "df[df[\"Title\"] == df_missing.iloc[1][\"Title\"]] = df[df[\"Title\"] == df_missing.iloc[1][\"Title\"]].replace(np.nan, \"Quentin Tarantino\")\n",
    "df[df[\"Title\"] == df_missing.iloc[2][\"Title\"]] = df[df[\"Title\"] == df_missing.iloc[2][\"Title\"]].replace(np.nan, \"7.5\")\n",
    "df[df[\"Title\"] == df_missing.iloc[3][\"Title\"]] = df[df[\"Title\"] == df_missing.iloc[3][\"Title\"]].replace(np.nan, \"2013\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8aaecb",
   "metadata": {},
   "source": [
    "2. Erroneous values\n",
    "\n",
    "In the following, we want to examine the attributes `Year` and `Rating` for potential erroneous values. Here, the rating is a number between 0 and 10 (inclusive) and the data covers the years from 2006 to 2016. A good approach to find erroneous values in numerical data is to visualize them. Therefore, create boxplots for the columns in question using `matplotlib` (see also [here](https://stackoverflow.com/questions/17725927/boxplots-in-matplotlib-markers-and-outliers))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc93b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# TODO: implement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddbf6fb",
   "metadata": {},
   "source": [
    "Through the plot outliers become visible, which give an indication of possibly erroneous values. Filter potential outlier values appropriately and store them in the DataFrame `df_outliers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fa935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a76e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_outliers)\n",
    "# Run tests\n",
    "unittest.main(argv=['ignored', '-v', 'OutliersTest'], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ceba80",
   "metadata": {},
   "source": [
    "Again, check [IMDB.com](https://www.imdb.com/) for the entries with potential erroneous values and manually correct them in the DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b3a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
